# RunCoach AI - API Python Backend

## ğŸš€ Overview

Backend API Python avec FastAPI pour les analyses avancÃ©es de donnÃ©es de course Ã  pied utilisant l'intelligence artificielle et le machine learning.

## ğŸ›  Technologies utilisÃ©es

- **FastAPI** - Framework web moderne et rapide
- **Python 3.11** - Langage de programmation
- **scikit-learn** - Machine Learning
- **pandas/numpy** - Manipulation de donnÃ©es
- **TensorFlow/Keras** - Deep Learning (optionnel)
- **Kaggle API** - Datasets de rÃ©fÃ©rence
- **Docker** - Conteneurisation

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.11+
- Docker (optionnel)
- Node.js 18+ (pour le frontend)

### Installation locale

```bash
# Cloner le repository
cd packages/api

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos paramÃ¨tres
```

### Installation Docker

```bash
# Build et lancement avec Docker Compose
docker-compose up --build

# Ou build manuel
docker build -t runcoach-api .
docker run -p 8000:8000 runcoach-api
```

## ğŸ”§ Configuration

### Variables d'environnement

```bash
SECRET_KEY=your-secret-key-here
DATABASE_URL=sqlite:///./runcoach.db
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
KAGGLE_USERNAME=your_kaggle_username
KAGGLE_KEY=your_kaggle_api_key
CORS_ORIGINS=http://localhost:5173,http://localhost:3000
```

### Configuration Kaggle (optionnelle)

Pour utiliser les datasets Kaggle :

1. CrÃ©er un compte sur [kaggle.com](https://kaggle.com)
2. Aller dans Account â†’ API â†’ Create New API Token
3. TÃ©lÃ©charger le fichier `kaggle.json`
4. Configurer les variables `KAGGLE_USERNAME` et `KAGGLE_KEY`

## ğŸš€ Lancement

### DÃ©veloppement

```bash
# Mode dÃ©veloppement avec rechargement automatique
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Ou avec les logs dÃ©taillÃ©s
python -m uvicorn main:app --reload --log-level debug
```

### Production

```bash
# Lancement production
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4

# Avec Gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Docker

```bash
# Avec Docker Compose (recommandÃ©)
docker-compose up

# Build et run manuel
docker build -t runcoach-api .
docker run -p 8000:8000 -e SECRET_KEY=your-secret-key runcoach-api
```

## ğŸ“Š API Endpoints

### Health Check

```bash
GET /health
# Response: {"status": "healthy", "version": "1.0.0"}
```

### Analyse d'entraÃ®nement

```bash
POST /analyze/workout
Content-Type: application/json

[
  {
    "id": "workout_1",
    "date": "2024-01-15",
    "type": "endurance",
    "duration": 45,
    "distance": 8.5,
    "pace": "5:30",
    "heart_rate": 150
  }
]
```

### Analyse des tendances

```bash
POST /analyze/performance-trend
Content-Type: application/json

# MÃªme format que /analyze/workout avec historique complet
```

### PrÃ©diction de performance

```bash
POST /predict/performance
Content-Type: application/json

{
  "workout_history": [...],
  "target_distance": 10.0,
  "target_date": "2024-06-15"
}
```

### Analyse des zones d'entraÃ®nement

```bash
POST /analyze/training-zones
Content-Type: application/json

# Historique d'entraÃ®nements pour analyser la distribution
```

### Ã‰valuation risque de blessure

```bash
POST /analyze/injury-risk
Content-Type: application/json

# Historique d'entraÃ®nements rÃ©cents
```

### Comparaison profil athlÃ¨te

```bash
POST /compare/athlete-profile
Content-Type: application/json

{
  "user_workouts": [...],
  "age": 35,
  "gender": "male",
  "experience_level": "intermediate"
}
```

### DonnÃ©es de rÃ©fÃ©rence

```bash
GET /datasets/running-benchmarks
# Retourne les donnÃ©es de rÃ©fÃ©rence Kaggle
```

## ğŸ§  Intelligence Artificielle

### Analyses disponibles

1. **Score de qualitÃ© d'entraÃ®nement** - IA Ã©value la session (0-100)
2. **PrÃ©diction de performance** - ML prÃ©dit les temps de course
3. **DÃ©tection des tendances** - Analyse l'Ã©volution de la forme
4. **Ã‰valuation des risques** - PrÃ©vention des blessures
5. **Comparaison avec peers** - Benchmarking avec datasets publics
6. **Zones d'entraÃ®nement** - Optimisation de la rÃ©partition des intensitÃ©s

### Algorithmes utilisÃ©s

- **Random Forest** - PrÃ©dictions de temps de course
- **Gradient Boosting** - Analyse des tendances de performance
- **RÃ©seaux de neurones** - Scoring complexe des entraÃ®nements
- **Clustering** - DÃ©tection de patterns comportementaux
- **SÃ©rie temporelles** - PrÃ©vision des cycles de forme

### Datasets de rÃ©fÃ©rence

- **Kaggle Running Performance** - DonnÃ©es de courses publiques
- **Elite Athletes Data** - Benchmarks athlÃ¨tes de haut niveau
- **Age Group Standards** - Standards par Ã¢ge et genre
- **Training Load Research** - Recherche scientifique sur la charge

## ğŸ”— IntÃ©gration Frontend

### Service TypeScript

```typescript
import { apiService } from '../services/apiService';

// Analyse d'entraÃ®nement
const analysis = await apiService.analyzeWorkout(workouts);

// PrÃ©diction
const prediction = await apiService.predictPerformance(
  workouts,
  10.0,
  '2024-06-15'
);
```

### Hook React

```typescript
import { useAdvancedAnalytics } from '../hooks/useAdvancedAnalytics';

const {
  isApiConnected,
  analyzeLatestWorkout,
  workoutAnalysis
} = useAdvancedAnalytics();
```

## ğŸ“ Structure du projet

```
packages/api/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e FastAPI
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ Dockerfile             # Configuration Docker
â”œâ”€â”€ docker-compose.yml     # Services Docker
â”œâ”€â”€ .env.example          # Variables d'environnement exemple
â”œâ”€â”€ models/               # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ workout.py        # ModÃ¨les d'entraÃ®nement
â”‚   â””â”€â”€ user.py          # ModÃ¨les utilisateur
â”œâ”€â”€ services/            # Logique mÃ©tier
â”‚   â”œâ”€â”€ ai_analytics.py  # Service IA principal
â”‚   â”œâ”€â”€ ml_predictor.py  # PrÃ©dictions ML
â”‚   â”œâ”€â”€ kaggle_service.py # IntÃ©gration Kaggle
â”‚   â””â”€â”€ workout_service.py # Gestion workouts
â”œâ”€â”€ database/           # Gestion donnÃ©es
â”‚   â””â”€â”€ connection.py   # Connexion DB
â””â”€â”€ data/              # Cache et datasets
    â””â”€â”€ kaggle_benchmarks.json
```

## ğŸ§ª Tests et dÃ©veloppement

### Tests unitaires

```bash
# Installer pytest
pip install pytest pytest-asyncio

# Lancer les tests
pytest tests/ -v

# Avec coverage
pytest tests/ --cov=. --cov-report=html
```

### Tests d'intÃ©gration

```bash
# Test des endpoints
curl -X POST http://localhost:8000/analyze/workout \
  -H "Content-Type: application/json" \
  -d @test_data/sample_workout.json

# Test de santÃ©
curl http://localhost:8000/health
```

### Debugging

```bash
# Mode debug avec logs dÃ©taillÃ©s
python -m uvicorn main:app --reload --log-level debug

# Profiling des performances
python -m cProfile -o profile_output.prof main.py
```

## ğŸš€ DÃ©ploiement

### DÃ©veloppement local

1. Lancer l'API : `uvicorn main:app --reload`
2. Lancer le frontend : `cd ../web && npm run dev`
3. AccÃ©der Ã  l'app : `http://localhost:5173`

### Production

```bash
# Avec Docker Compose
docker-compose -f docker-compose.prod.yml up -d

# Avec reverse proxy nginx
# Configurer nginx pour proxy_pass vers :8000
```

### Surveillance

- Logs : `/app/logs/`
- MÃ©triques : `/metrics` (Prometheus)
- Health : `/health`

## ğŸ“ˆ Performance et optimisation

### Mise en cache

- Cache Redis pour les analyses frÃ©quentes
- Cache local pour les benchmarks Kaggle
- Invalidation automatique aprÃ¨s 24h

### Optimisations ML

- ModÃ¨les prÃ©-entraÃ®nÃ©s sauvegardÃ©s
- Batch processing pour analyses multiples
- Calculs asynchrones pour UI responsive

### Monitoring

```python
# MÃ©triques personnalisÃ©es
from prometheus_client import Counter, Histogram

ANALYSIS_COUNTER = Counter('analysis_requests_total')
ANALYSIS_TIME = Histogram('analysis_duration_seconds')
```

## ğŸ”’ SÃ©curitÃ©

### Authentification

- JWT tokens pour sessions
- Rate limiting par IP
- Validation stricte des inputs
- Sanitisation des donnÃ©es

### Protection donnÃ©es

- Pas de stockage permanent des donnÃ©es utilisateur
- Chiffrement des communications (HTTPS)
- Logs anonymisÃ©s
- ConformitÃ© RGPD

## ğŸ“š Documentation API

### Swagger/OpenAPI

- Documentation interactive : `http://localhost:8000/docs`
- SchÃ©ma OpenAPI : `http://localhost:8000/openapi.json`
- ReDoc alternative : `http://localhost:8000/redoc`

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit les changements (`git commit -m 'Add amazing feature'`)
4. Push la branche (`git push origin feature/amazing-feature`)
5. CrÃ©er une Pull Request

## ğŸ“„ License

MIT License - voir le fichier [LICENSE](LICENSE) pour les dÃ©tails.

## ğŸ› Support

- Issues GitHub : [CrÃ©er un ticket](../../issues)
- Documentation : [Wiki du projet](../../wiki)
- Email : support@runcoach-ai.com